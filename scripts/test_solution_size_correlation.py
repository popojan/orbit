#!/usr/bin/env python3
"""
CRITICAL TEST: Is Wildberger path length just measuring solution size?

Question: Is path_length ~ log(x‚ÇÄ)?
If YES: We're just measuring regulator R(d) (well-studied, boring)
If NO: Path length has independent structure (interesting!)

Also tests residual variance after fitting Wild = Œ±√óCF + Œµ
"""

import math
import statistics


def pellsol(d):
    """Wildberger algorithm - returns solution and path length"""
    a, b, c = 1, 0, -d
    u, v, r, s = 1, 0, 0, 1
    path_len = 0

    while True:
        t = a + b + b + c
        if t > 0:
            a = t; b += c; u += v; r += s
        else:
            b += a; c = t; v += u; s += r
        path_len += 1

        if a == 1 and b == 0 and c == -d:
            break

    return (u, r), path_len


def cf_period(d):
    """Continued fraction period for ‚àöd"""
    if int(math.sqrt(d))**2 == d:
        return None

    m, d_val, a = 0, 1, int(math.sqrt(d))
    a0, seen, period_len = a, {}, 0

    while True:
        key = (m, d_val, a)
        if key in seen:
            return period_len - seen[key]
        seen[key] = period_len

        m = d_val * a - m
        d_val = (d - m * m) // d_val
        a = (a0 + m) // d_val
        period_len += 1

        if period_len > 1000:
            break
    return period_len


def correlation(xs, ys):
    """Pearson correlation"""
    n = len(xs)
    mean_x, mean_y = sum(xs)/n, sum(ys)/n
    num = sum((x - mean_x) * (y - mean_y) for x, y in zip(xs, ys))
    denom = math.sqrt(sum((x - mean_x)**2 for x in xs) * sum((y - mean_y)**2 for y in ys))
    return num / denom if denom != 0 else 0


print("="*80)
print("CRITICAL TEST: Solution Size vs Path Length Correlation")
print("="*80)
print()

# Collect data
data = []
for d in range(2, 301):
    if int(math.sqrt(d))**2 == d:
        continue

    sol, wild = pellsol(d)
    cf = cf_period(d)
    if cf is None or cf == 0:
        continue

    x0, y0 = sol
    log_x = math.log(x0)
    regulator = log_x + 0.5 * math.log(d)  # Approximation: R(d) ‚âà log(x‚ÇÄ + y‚ÇÄ‚àöd) ‚âà log(x‚ÇÄ) + 0.5*log(d)

    data.append({
        'd': d,
        'wild': wild,
        'cf': cf,
        'x0': x0,
        'y0': y0,
        'log_x': log_x,
        'regulator': regulator,
        'alpha': wild / cf
    })

print(f"Sample size: n = {len(data)}")
print()

# Extract arrays
wilds = [item['wild'] for item in data]
cfs = [item['cf'] for item in data]
log_xs = [item['log_x'] for item in data]
regulators = [item['regulator'] for item in data]
alphas = [item['alpha'] for item in data]

# ============================================================================
# TEST 1: Is path length just measuring solution size?
# ============================================================================
print("="*80)
print("TEST 1: PATH LENGTH vs SOLUTION SIZE")
print("="*80)

corr_wild_logx = correlation(wilds, log_xs)
corr_cf_logx = correlation(cfs, log_xs)
corr_wild_reg = correlation(wilds, regulators)

print(f"Correlation Wild path vs log(x‚ÇÄ):     {corr_wild_logx:>7.4f}")
print(f"Correlation CF period vs log(x‚ÇÄ):     {corr_cf_logx:>7.4f}")
print(f"Correlation Wild path vs R(d):        {corr_wild_reg:>7.4f}")
print()

if abs(corr_wild_logx) > 0.8:
    print("‚ùå HIGH CORRELATION: Wild path is just measuring solution size!")
    print("   ‚Üí This means we're NOT discovering anything new")
    print("   ‚Üí Path length ‚âà function of regulator R(d)")
elif abs(corr_wild_logx) > 0.5:
    print("‚ö†Ô∏è  MODERATE CORRELATION: Path length partially determined by x‚ÇÄ")
    print("   ‚Üí But there's additional structure beyond solution size")
elif abs(corr_wild_logx) > 0.3:
    print("‚óê WEAK CORRELATION: Some connection to solution size")
    print("   ‚Üí But path length has significant independent structure")
else:
    print("‚úÖ LOW CORRELATION: Path length is INDEPENDENT of solution size!")
    print("   ‚Üí This is genuinely interesting!")
print()

# Compare CF vs Wild correlation with log(x‚ÇÄ)
print("Which is more correlated with solution size?")
print(f"  Wild - log(x‚ÇÄ) correlation: {abs(corr_wild_logx):.4f}")
print(f"  CF - log(x‚ÇÄ) correlation:   {abs(corr_cf_logx):.4f}")
if abs(corr_wild_logx) > abs(corr_cf_logx) + 0.1:
    print("  ‚Üí Wild is MORE correlated than CF (Wildberger adds size dependence)")
elif abs(corr_cf_logx) > abs(corr_wild_logx) + 0.1:
    print("  ‚Üí CF is MORE correlated than Wild (surprising!)")
else:
    print("  ‚Üí Similar correlation (both measure similar complexity)")
print()

# ============================================================================
# TEST 2: Residual variance after fitting Wild = Œ± √ó CF
# ============================================================================
print("="*80)
print("TEST 2: RESIDUAL ANALYSIS (Off-by-one test)")
print("="*80)

# Compute optimal Œ± via least squares: Œ± = Œ£(Wild√óCF) / Œ£(CF¬≤)
alpha_optimal = sum(w * c for w, c in zip(wilds, cfs)) / sum(c**2 for c in cfs)
print(f"Optimal scaling factor: Œ±‚ÇÄ = {alpha_optimal:.4f}")
print()

# Compute residuals: Œµ = Wild - Œ±‚ÇÄ √ó CF
residuals = [w - alpha_optimal * c for w, c in zip(wilds, cfs)]

mean_res = statistics.mean(residuals)
std_res = statistics.stdev(residuals)
abs_residuals = [abs(r) for r in residuals]
mean_abs_res = statistics.mean(abs_residuals)
max_abs_res = max(abs_residuals)

print(f"Residuals Œµ = Wild - {alpha_optimal:.3f}√óCF:")
print(f"  Mean Œµ:        {mean_res:>8.3f}")
print(f"  Std dev Œµ:     {std_res:>8.3f}")
print(f"  Mean |Œµ|:      {mean_abs_res:>8.3f}")
print(f"  Max |Œµ|:       {max_abs_res:>8.3f}")
print()

# Key test: Is std(Œµ) ~ O(1)? (User's "off by one" hypothesis)
if std_res < 2.0:
    print("‚úÖ EXCELLENT: std(Œµ) < 2 ‚Üí Wild ‚âà Œ±√óCF + O(1)")
    print("   ‚Üí Wildberger path is ALMOST EXACTLY a constant multiple of CF period!")
    print("   ‚Üí Only constant additive noise")
elif std_res < 5.0:
    print("‚úì GOOD: std(Œµ) ~ O(1) ‚Üí Wild ‚âà Œ±√óCF with small deviations")
    print("   ‚Üí Linear relationship with bounded noise")
elif std_res < 10.0:
    print("‚óê MODERATE: std(Œµ) ~ O(1-10) ‚Üí Some systematic deviation")
    print("   ‚Üí Not perfectly linear, but close")
else:
    print("‚úó LARGE: std(Œµ) >> 1 ‚Üí Wild ‚â† simple linear function of CF")
    print("   ‚Üí Significant non-linear or additional structure")
print()

# Distribution of residuals
print("Residual distribution (how far off from Œ±√óCF?):")
print(f"  |Œµ| < 1:       {sum(1 for r in abs_residuals if r < 1):3d} ({100*sum(1 for r in abs_residuals if r < 1)/len(residuals):.1f}%)")
print(f"  |Œµ| < 2:       {sum(1 for r in abs_residuals if r < 2):3d} ({100*sum(1 for r in abs_residuals if r < 2)/len(residuals):.1f}%)")
print(f"  |Œµ| < 5:       {sum(1 for r in abs_residuals if r < 5):3d} ({100*sum(1 for r in abs_residuals if r < 5)/len(residuals):.1f}%)")
print(f"  |Œµ| >= 5:      {sum(1 for r in abs_residuals if r >= 5):3d} ({100*sum(1 for r in abs_residuals if r >= 5)/len(residuals):.1f}%)")
print()

# Find worst outliers
outliers = [(data[i]['d'], residuals[i], wilds[i], cfs[i])
            for i in range(len(residuals))
            if abs(residuals[i]) > 2 * std_res]
if outliers:
    print(f"Outliers (|Œµ| > 2œÉ = {2*std_res:.2f}):")
    for d, eps, w, c in sorted(outliers, key=lambda x: abs(x[1]), reverse=True)[:10]:
        print(f"  d={d:3d}: Œµ={eps:>6.2f}, Wild={w:3d}, CF={c:2d}, Wild/CF={w/c:.2f}")
    print()

# ============================================================================
# TEST 3: Correlation matrix
# ============================================================================
print("="*80)
print("TEST 3: CORRELATION MATRIX")
print("="*80)
print()

variables = {
    'Wild': wilds,
    'CF': cfs,
    'log(x‚ÇÄ)': log_xs,
    'R(d)': regulators,
    'Œ±': alphas
}

print("       ", "  ".join(f"{name:>8s}" for name in variables.keys()))
print("-" * 60)
for name1, vals1 in variables.items():
    corrs = []
    for name2, vals2 in variables.items():
        c = correlation(vals1, vals2)
        corrs.append(f"{c:>8.4f}")
    print(f"{name1:>7s}  " + "  ".join(corrs))
print()

# ============================================================================
# FINAL VERDICT
# ============================================================================
print("="*80)
print("FINAL VERDICT")
print("="*80)
print()

score = 0

# Factor 1: Independence from solution size
if abs(corr_wild_logx) < 0.3:
    score += 2
    print("‚úÖ Path length INDEPENDENT of solution size (exciting!)")
elif abs(corr_wild_logx) < 0.6:
    score += 1
    print("‚óê Path length WEAKLY depends on solution size")
else:
    print("‚ùå Path length STRONGLY depends on solution size (boring)")

# Factor 2: Residual variance
if std_res < 2.0:
    score += 2
    print("‚úÖ Wild ‚âà Œ±√óCF + O(1) with VERY small noise")
elif std_res < 5.0:
    score += 1
    print("‚óê Wild ‚âà Œ±√óCF + O(1) with moderate noise")
else:
    print("‚ùå Wild ‚â† simple linear function of CF")

# Factor 3: Œ± variance meaningful
cv_alpha = statistics.stdev(alphas) / statistics.mean(alphas)
if cv_alpha > 0.3:
    score += 1
    print(f"‚úì Œ±(d) has HIGH variance (CV={cv_alpha:.3f}) - interesting pattern")
elif cv_alpha > 0.1:
    print(f"‚óê Œ±(d) has MODERATE variance (CV={cv_alpha:.3f})")
else:
    print(f"‚úó Œ±(d) has LOW variance (CV={cv_alpha:.3f}) - mostly constant")

print()
print(f"SCORE: {score}/5")
print()

if score >= 4:
    print("üéâ VERDICT: Path length has GENUINE independent structure!")
    print("   ‚Üí NOT just restating solution size")
    print("   ‚Üí Wild ‚âà Œ±(d)√óCF where Œ±(d) varies meaningfully")
    print("   ‚Üí Worth investigating what determines Œ±(d)")
elif score >= 2:
    print("ü§î VERDICT: Mixed results")
    print("   ‚Üí Some independent structure, but partially tied to solution size")
    print("   ‚Üí May still be interesting")
else:
    print("üòê VERDICT: Probably just measuring known quantities")
    print("   ‚Üí Path length ‚âà function of solution size")
    print("   ‚Üí Not discovering anything new")

print()
print("="*80)
