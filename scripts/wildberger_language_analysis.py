#!/usr/bin/env python3
"""
Chomsky Hierarchy Analysis of Wildberger LR Sequences

Goal: Characterize the formal language L_W of branch strings
generated by Wildberger's Pell algorithm.

Known facts:
1. All strings are palindromes (Wildberger's theorem)
2. NOT all palindromes are in L_W (counterexample: +--+)
3. First symbol is always '-' for d ≥ 2 (non-square)
4. Strings encode path to fundamental Pell solution

Questions:
- What is the grammar for L_W?
- Is it context-free? Deterministic CF?
- What additional constraints exist?
- Connection to binomial structure C(3i, 2i)?
"""

from wildberger_pell_trace import wildberger_pell

def extract_lr_string(trace):
    """Extract LR branch sequence from trace"""
    return ''.join([step[1] for step in trace])

def is_palindrome(s):
    """Check if string is palindrome"""
    return s == s[::-1]

def analyze_string_structure(s):
    """Analyze structural properties of LR string"""
    n = len(s)
    plus_count = s.count('+')
    minus_count = s.count('-')

    # Find all runs
    runs = []
    if n > 0:
        current_char = s[0]
        current_len = 1
        for i in range(1, n):
            if s[i] == current_char:
                current_len += 1
            else:
                runs.append((current_char, current_len))
                current_char = s[i]
                current_len = 1
        runs.append((current_char, current_len))

    # Compute run-length encoding
    rle = ''.join([f"{char}{length}" if length > 1 else char for char, length in runs])

    # Find center
    if n % 2 == 0:
        center = None
        left_half = s[:n//2]
        right_half = s[n//2:]
    else:
        center = s[n//2]
        left_half = s[:n//2]
        right_half = s[n//2+1:]

    return {
        'length': n,
        'plus_count': plus_count,
        'minus_count': minus_count,
        'runs': runs,
        'rle': rle,
        'center': center,
        'left_half': left_half,
        'right_half': right_half,
        'is_palindrome': is_palindrome(s),
        'first_char': s[0] if n > 0 else None,
        'last_char': s[-1] if n > 0 else None
    }

def collect_all_strings(d_values):
    """Collect all Wildberger strings for given d values"""
    strings_data = []

    for d in d_values:
        try:
            x, y, trace = wildberger_pell(d, verbose=False)
            lr_string = extract_lr_string(trace)
            analysis = analyze_string_structure(lr_string)

            strings_data.append({
                'd': d,
                'string': lr_string,
                'analysis': analysis,
                'fundamental_solution': (x, y)
            })
        except Exception as e:
            print(f"Error for d={d}: {e}")
            continue

    return strings_data

def print_string_table(strings_data):
    """Print formatted table of all strings"""
    print("="*100)
    print("WILDBERGER LR STRINGS - COMPLETE COLLECTION")
    print("="*100)

    print(f"\n{'d':<6} {'Len':<6} {'+':<6} {'-':<6} {'Pal?':<6} {'String'}")
    print("-"*100)

    for data in strings_data:
        d = data['d']
        s = data['string']
        a = data['analysis']

        pal = "✓" if a['is_palindrome'] else "✗"

        print(f"{d:<6} {a['length']:<6} {a['plus_count']:<6} {a['minus_count']:<6} {pal:<6} {s}")

def verify_universal_properties(strings_data):
    """Verify properties that should hold for all strings"""
    print("\n" + "="*100)
    print("UNIVERSAL PROPERTIES CHECK")
    print("="*100)

    all_palindromes = all(data['analysis']['is_palindrome'] for data in strings_data)
    all_start_minus = all(data['analysis']['first_char'] == '-' for data in strings_data)
    all_end_minus = all(data['analysis']['last_char'] == '-' for data in strings_data)

    print(f"\n1. All palindromes: {all_palindromes}")
    print(f"2. All start with '-': {all_start_minus}")
    print(f"3. All end with '-': {all_end_minus}")

    if all_palindromes and all_start_minus:
        print("\n✓ Confirmed: Palindrome property ensures first = last = '-'")

    # Check length patterns
    lengths = [data['analysis']['length'] for data in strings_data]
    print(f"\n4. Length range: {min(lengths)} to {max(lengths)}")
    print(f"   Lengths: {sorted(set(lengths))}")

    # Check symmetry
    symmetric = [data for data in strings_data if data['analysis']['plus_count'] == data['analysis']['minus_count']]
    asymmetric = [data for data in strings_data if data['analysis']['plus_count'] != data['analysis']['minus_count']]

    print(f"\n5. Symmetric strings (+ = -): {len(symmetric)}/{len(strings_data)}")
    print(f"   Asymmetric strings: {len(asymmetric)}/{len(strings_data)}")

def find_grammar_patterns(strings_data):
    """Try to identify grammar rules"""
    print("\n" + "="*100)
    print("GRAMMAR PATTERN ANALYSIS")
    print("="*100)

    # Group by structure type
    print("\n1. RUN-LENGTH ENCODING PATTERNS")
    print("-"*100)

    rle_patterns = {}
    for data in strings_data:
        rle = data['analysis']['rle']
        if rle not in rle_patterns:
            rle_patterns[rle] = []
        rle_patterns[rle].append(data['d'])

    # Show unique patterns
    print(f"\nFound {len(rle_patterns)} unique RLE patterns:")
    for rle, d_vals in sorted(rle_patterns.items(), key=lambda x: len(x[0])):
        if len(d_vals) > 1:
            print(f"  {rle:<30} appears for d = {d_vals}")

    # Analyze run structure
    print("\n2. RUN STRUCTURE ANALYSIS")
    print("-"*100)

    max_run_length = max(max(run[1] for run in data['analysis']['runs'])
                         for data in strings_data)
    print(f"\nMaximum run length: {max_run_length}")

    # Count run distributions
    run_counts = {}
    for data in strings_data:
        num_runs = len(data['analysis']['runs'])
        if num_runs not in run_counts:
            run_counts[num_runs] = []
        run_counts[num_runs].append(data['d'])

    print(f"\nNumber of runs distribution:")
    for num_runs in sorted(run_counts.keys()):
        print(f"  {num_runs} runs: {len(run_counts[num_runs])} strings (d = {run_counts[num_runs][:5]}...)")

    # Check for nested structure
    print("\n3. NESTED STRUCTURE (Center symmetry)")
    print("-"*100)

    for data in strings_data[:10]:  # Show first 10 as examples
        a = data['analysis']
        if a['center']:
            print(f"d={data['d']}: center='{a['center']}', left='{a['left_half']}', right='{a['right_half']}'")

def propose_grammar(strings_data):
    """Propose formal grammar for L_W"""
    print("\n" + "="*100)
    print("PROPOSED CONTEXT-FREE GRAMMAR")
    print("="*100)

    print("\nBased on observations:")
    print("1. All strings are palindromes")
    print("2. All strings start and end with '-'")
    print("3. Nested structure from palindrome property")

    print("\nProposed Grammar G = (V, Σ, R, S):")
    print("-"*50)
    print("V = {S, A, B}  (non-terminals)")
    print("Σ = {+, -}     (terminals)")
    print("S = start symbol")
    print("\nProduction Rules R:")
    print("  S → -A-      (enforce start/end with '-')")
    print("  A → -A-      (add matching '-' pair)")
    print("  A → +A+      (add matching '+' pair)")
    print("  A → ε        (empty, even length)")
    print("  A → +        (center '+', odd length)")
    print("  A → -        (center '-', odd length)")

    print("\n⚠️  NOTE: This is OVERGENERATING!")
    print("This grammar accepts ALL palindromes starting/ending with '-'")
    print("But L_W is a PROPER SUBSET with additional constraints from algorithm dynamics")

    print("\nTo capture L_W exactly, we likely need:")
    print("- Context-sensitive rules (constraints on run lengths)")
    print("- OR: Deterministic pushdown automaton with specific stack operations")
    print("- OR: Regular sublanguage with bounded complexity")

def test_counterexamples(strings_data):
    """Test if certain palindromes are NOT in L_W"""
    print("\n" + "="*100)
    print("COUNTEREXAMPLE SEARCH")
    print("="*100)

    print("\nKnown counterexample: '+--+' (starts with '+', violates constraint)")

    # Generate small palindromes and check if they appear
    actual_strings = set(data['string'] for data in strings_data)

    # Generate all palindromes up to length 6 starting with '-'
    def generate_palindromes(length):
        if length == 0:
            return ['']
        if length == 1:
            return ['-', '+']
        if length == 2:
            return ['--', '++']

        # Even length
        if length % 2 == 0:
            half = length // 2
            pals = []
            for i in range(2**half):
                left = ''.join(['+' if (i >> j) & 1 else '-' for j in range(half)])
                pals.append(left + left[::-1])
            return pals
        else:
            # Odd length
            half = length // 2
            pals = []
            for center in ['-', '+']:
                for i in range(2**half):
                    left = ''.join(['+' if (i >> j) & 1 else '-' for j in range(half)])
                    pals.append(left + center + left[::-1])
            return pals

    print("\nSearching for palindromes (starting with '-') NOT in L_W:")
    print("-"*50)

    found_counterexamples = []
    for length in range(2, 8):
        candidates = [p for p in generate_palindromes(length) if p.startswith('-')]
        for candidate in candidates:
            if candidate not in actual_strings:
                found_counterexamples.append((length, candidate))
                if len(found_counterexamples) <= 10:  # Show first 10
                    print(f"  Length {length}: '{candidate}' NOT in L_W")

    print(f"\nTotal counterexamples found (length 2-7): {len(found_counterexamples)}")
    print("\n✓ Confirmed: L_W is PROPER SUBSET of palindromes starting with '-'")

if __name__ == "__main__":
    # Test cases: all d values we've analyzed
    d_values = [2, 3, 5, 6, 7, 10, 11, 13, 14, 15, 17, 19, 21, 23, 29, 31, 37, 41, 43, 47, 53, 61]

    print("Collecting Wildberger LR strings...")
    strings_data = collect_all_strings(d_values)

    print_string_table(strings_data)
    verify_universal_properties(strings_data)
    find_grammar_patterns(strings_data)
    propose_grammar(strings_data)
    test_counterexamples(strings_data)

    print("\n" + "="*100)
    print("CONCLUSION")
    print("="*100)
    print("\nWildberger language L_W:")
    print("- ✓ Context-Free (palindromes are CF)")
    print("- ✓ Proper subset of CF palindrome language")
    print("- ? Exact characterization requires understanding algorithm constraints")
    print("- ? Possibly regular with bounded complexity (finite state?)")
    print("- ? Connection to binomial C(3i,2i) structure unclear")
    print("\nNext steps:")
    print("1. Analyze transition dynamics (a,b,c) to derive additional rules")
    print("2. Check if L_W is regular (build DFA/NFA)")
    print("3. Explore connection to Stern-Brocot tree paths")
    print("4. Link to negative Pell existence (even-length palindromes)")
