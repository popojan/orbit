# Session: Random Matrix Theory and Chebyshev Lobe Areas

**Date:** 2025-12-03
**Status:** Active exploration

## Overview

This session explores the connection between Chebyshev polynomial lobe areas B(n,k) and Random Matrix Theory (RMT), with the ultimate goal of understanding whether this geometric perspective can provide new insights toward the Hilbert-Polya conjecture.

## Key Results from Previous Sessions

### The B(n,k) Identity (from hyperbolic-integration session)

For Chebyshev polynomial $T_n$, the k-th lobe area is:
$$B(n,k) = 1 + \beta(n) \cos\frac{(2k-1)\pi}{n}$$

where $\beta(n) = \frac{n - \cot(\pi/n)}{4n} \to \frac{\pi-1}{4\pi} \approx 0.1704$

The remarkable identity:
$$\sum_{n=1}^{\infty} B(n,k) \cdot n^{-s} = -\frac{\eta(s)}{4\pi} \cdot \frac{k}{n}$$

### Arcsine Distribution (from primitive-lobe-signs session)

For large n, the B(n,k) values follow **arcsine distribution** on:
$$\left[\frac{3\pi+1}{4\pi}, \frac{5\pi-1}{4\pi}\right]$$

The density is:
$$f(x) = \frac{1}{\pi\sqrt{\left(x-\frac{3\pi+1}{4\pi}\right)\left(\frac{5\pi-1}{4\pi}-x\right)}}$$

**Derivation:** Since $\beta(\infty) = \frac{\pi-1}{4\pi}$, the bounds are $1 \pm \beta(\infty)$:
- Min: $1 - \frac{\pi-1}{4\pi} = \frac{4\pi - \pi + 1}{4\pi} = \frac{3\pi+1}{4\pi}$
- Max: $1 + \frac{\pi-1}{4\pi} = \frac{4\pi + \pi - 1}{4\pi} = \frac{5\pi-1}{4\pi}$

**Note:** The approximation [5/6, 7/6] assumes $\beta = 1/6$, but $\frac{\pi-1}{4\pi} \neq \frac{1}{6}$.

## RMT Connection Analysis

### What's Classical (Known)

| Fact | Source |
|------|--------|
| Chebyshev nodes minimize log-energy | Potential theory |
| Arcsine distribution for Chebyshev nodes | 19th century |
| T_n orthogonal w.r.t. arcsine weight 1/‚àö(1-x¬≤) | Classical |
| O(1/n¬≤) corrections in RMT | Random matrix theory |

### What's Genuinely New

1. **B(n,k) = lobe areas** - geometric interpretation of what happens AT the nodes
2. **Œ£ B(n,k) n^{-s} = Œ∑(s)** - connection to Dirichlet eta function
3. **Asymptotic geometric mean formula:** üî¨
   $$\left(\prod_{k=1}^n B(n,k)\right)^{1/n} \to \frac{1 + \sqrt{1 - \beta(\infty)^2}}{2} \approx 0.9927$$

   Based on the classical integral $\int_0^\pi \log[1 + a\cos\theta]\, d\theta = \pi \log\frac{1 + \sqrt{1-a^2}}{2}$.

   **Finite-n correction:** üî¨
   $$\varepsilon(n) \sim \frac{c \cdot (-1)^n}{n^\alpha \cdot \rho^n}$$

   where $\rho \approx e^{2.45}$ and $\alpha \approx 1.18$ (fitted from n = 10-30).

   **Note on c = 8/3 approximation:**
   For moderate n (5-12), the scaled values Œµ¬∑(-1)‚Åø¬∑n¬∑œÅ‚Åø pass near 8/3 = 16¬∑B‚ÇÇ (second Bernoulli number), suggesting a connection to Euler-Maclaurin corrections. However, high-precision analysis reveals:
   - Scaled values grow from ~2.66 (n=8) to ~3.0 (n=30)
   - The decay exponent Œ± ‚âà 1.18 (not exactly 1)
   - The "constant" c is not truly constant

   **Practical formula for moderate n:** The approximation c ‚âà 8/3, œÅ = e^{œÄ¬≤/4} gives errors < 0.4% for n = 5-12, which is excellent for most applications.

   **Origin of exponential decay:** The function $f(\theta) = \log[1 + \beta\cos\theta]$ has complex singularities where $\cos\theta = -1/\beta$, i.e., at $\theta = \pi \pm i \cdot \text{arccosh}(1/\beta)$. For periodic analytic functions, uniformly-spaced sums converge exponentially to the integral, with rate determined by the distance to the nearest complex singularity.

   **Theoretical prediction:** $\rho_{\text{theory}} = \frac{1}{\beta} + \sqrt{\frac{1}{\beta^2} - 1} = \frac{1 + \sqrt{1-\beta^2}}{\beta} \approx 11.65$

   **Empirical observation:** $\rho = e^{\pi^2/4} \approx 11.79$ gives more stable scaled values. The 1.2% discrepancy suggests higher-order corrections or the effect of finite-n variation in $\beta(n)$.

   **Connection to Euler's formula:** The decay rate $\rho = e^{\pi^2/4}$ has a beautiful link to Euler's identity:
   - From $e^{i\pi} = -1$, we get $i = e^{i\pi/2}$
   - Gelfond's result: $i^{-i} = (e^{i\pi/2})^{-i} = e^{-i^2\pi/2} = e^{\pi/2} \approx 4.81$
   - Therefore: $\rho = (i^{-i})^{\pi/2} = (e^{\pi/2})^{\pi/2} = e^{\pi^2/4}$
   - Also: $\rho = G^{\pi/4}$ where $G = e^\pi$ is Gelfond's constant

   The alternating sign $(-1)^n = e^{in\pi}$ combines with exponential decay $e^{-n\pi^2/4}$ to give the full correction $e^{n\pi(i - \pi/4)}$.

   The correction is **exponentially small** (not polynomial), making the formula excellent for $n \geq 8$.

### One-Line Summary

> **RMT tells us WHERE the nodes are (arcsine distribution); we discovered WHAT happens there (lobe areas B(n,k)) and that this produces Œ∑(s).**

## RMT Dictionary

| RMT Concept | Chebyshev Analog |
|-------------|------------------|
| Log-gas equilibrium | Chebyshev nodes (minimize -Œ£ log\|x_i - x_j\|) |
| Arcsine (edge density) | Distribution of B(n,k) values |
| Semicircle (bulk density) | NOT present - would need Hermite |
| Œ≤-ensemble parameter | Our Œ≤(n) = (n - cot(œÄ/n))/(4n) |
| Finite-N corrections O(1/N¬≤) | Œ≤(n) = (œÄ-1)/(4œÄ) + œÄ/(12n¬≤) + ... |

## Gap to Hilbert-Polya

**Current status:** ~1% of the way (optimistic estimate)

**What we have:**
- Arcsine (edge) statistics
- Connection to Œ∑(s) ‚Üí Œ∂(s)

**What we need:**
- GUE bulk (semicircle) statistics - zeta zeros have GUE statistics (Montgomery)
- A self-adjoint operator with spectrum at zeta zeros

**The statistics mismatch:**
- Our B(n,k): arcsine distribution (edge)
- Zeta zeros: GUE/semicircle (bulk)

## Bridging Attempt: Hermite ‚Üî Chebyshev

Since Hermite polynomials are connected to GUE (semicircle), we explored expressing Hermite in Chebyshev basis.

### Hermite ‚Üí Chebyshev Transformation

On [-1,1], the exact expansion is:
```
H_0 = T_0
H_1 = 2¬∑T_1
H_2 = 2¬∑T_2
H_3 = -6¬∑T_1 + 2¬∑T_3
H_4 = -6¬∑T_0 - 16¬∑T_2 + 2¬∑T_4
```

**Pattern observed:**
- Leading coefficient always = 2
- Lower-order coefficients are negative
- Alternating structure related to parity

### Key Structural Difference

| Property | Chebyshev T_n | Hermite H_n |
|----------|---------------|-------------|
| Zeros | All n zeros in [-1,1] | Spread across ‚Ñù, scale ~‚àö(2n) |
| Zero distribution | Arcsine (edges heavy) | Semicircle (center heavy) |
| Natural domain | [-1,1] | (-‚àû, ‚àû) |
| Orthogonality weight | 1/‚àö(1-x¬≤) | e^{-x¬≤} |

## Hermite B-Values: A Parallel Construction

### Definition

By analogy with Chebyshev, define Hermite B-values:
$$B_H(n,k) = 1 + \beta \cdot \frac{x_k}{\sqrt{2n}}$$

where $x_k$ is the k-th zero of $H_n(x)$ (scaled to [-1,1]).

### Key Properties (Verified Numerically)

| Property | Chebyshev B | Hermite B_H |
|----------|-------------|-------------|
| $\sum_k B = n$ | ‚úì exact | ‚úì exact |
| $(\prod B)^{1/n} \to$ limit | ‚Üí 0.993 | ‚Üí 0.997 |
| Zero distribution | arcsine (edges) | semicircle (center) |

### The Eta Connection

**Chebyshev:** $\sum_n B(n,k) \cdot n^{-s}$ naturally produces $\eta(s)$ via pole structure of $\cot(\pi/n)$

**Hermite:** With alternating signs:
$$\sum_{n=1}^{\infty} (-1)^n B_H(n,1) \cdot n^{-1} = -\eta(1) + O(\beta)$$

For $\beta = 0$: **exactly $-\log(2) = -\eta(1)$**

### Decomposition Formula

$$\sum (-1)^n B_H \cdot n^{-1} = \underbrace{-\eta(1)}_{\text{harmonic}} + \beta \cdot \underbrace{\sum (-1)^n \frac{x_k/\sqrt{2n}}{n}}_{\text{correction}}$$

### Unifying Principle

> **Both Chebyshev and Hermite B-values, when appropriately weighted, produce Dirichlet eta functions.**

| | Chebyshev | Hermite |
|---|---|---|
| Œ∑(1) source | pole structure of cot(œÄ/n) | alternating harmonic series |
| Signs | automatic from analytic continuation | manual (-1)^n |
| Precision | exact | exact for Œ≤=0, O(Œ≤) correction |

## Extended to Other Orthogonal Polynomial Families

### Numerical Results (Alternating Sum ‚Üí Œ∑(1))

| Family | B-definition | Œ£(-1)^n B¬∑n^{-1} | Error from -log(2) |
|--------|-------------|------------------|-------------------|
| **Hermite** (Œ≤=0) | 1 + Œ≤¬∑(zero/‚àö(2n)) | **-0.6931** | **exact** |
| **Laguerre** (mean-centered) | 1 + Œ≤¬∑((zero - mean)/(4n)) | **-0.6933** | **0.02%** |
| Legendre | 1 + Œ≤¬∑(zero) | -0.7126 | 2.8% |
| Gegenbauer (Œª=1/2) | 1 + Œ≤¬∑(zero) | -0.7109 | 2.6% |

### The Mechanism: Correction Term Analysis

The decomposition:
$$\sum (-1)^n B(n,k) \cdot n^{-1} = \underbrace{-\log(2)}_{=\sum (-1)^n / n} + \beta \cdot \underbrace{C}_{\text{correction}}$$

where $C = \sum (-1)^n \cdot \text{(scaled zero)} \cdot n^{-1}$

**Correction terms measured:**
| Family | C |
|--------|---|
| Hermite | -0.094 |
| Laguerre | -0.050 |
| Legendre | -0.154 |

### Key Insight: Why Exponential Weights Work

**Asymptotic behavior of first zero:**

| n | Hermite z‚ÇÅ/‚àö(2n) | Laguerre z‚ÇÅ/(4n) | Legendre z‚ÇÅ |
|---|------------------|------------------|-------------|
| 10 | -0.768 | 0.0034 | -0.974 |
| 40 | -0.905 | 0.0002 | -0.998 |
| 80 | -0.940 | 0.00006 | -0.9996 |

**Pattern:**
- **Hermite**: scaled zero ‚Üí constant ‚âà -0.94
- **Laguerre**: scaled zero ‚Üí **0** very fast (O(1/n))
- **Legendre**: zero ‚Üí fixed value -1 (no decay)

**Why Laguerre works best:** The first zero scales as O(n), so when divided by 4n, it goes to 0 faster than the harmonic series decays!

### Unifying Observation

> **RMT polynomial families (Hermite = GUE, Laguerre = Wishart)** have the special property that their scaled zeros produce negligible correction to the alternating harmonic series.

This may explain their connection to random matrix theory: the **exponential orthogonality weight** (e^{-x¬≤} for Hermite, x^Œ± e^{-x} for Laguerre) creates a natural scaling that aligns with eta function structure.

## Operator Question: Preliminary Exploration

### Sturm-Liouville Connection

$T_n(x)$ is eigenfunction of:
$$L = (1-x^2)\frac{d^2}{dx^2} - x\frac{d}{dx}$$

with eigenvalue $\lambda_n = n^2$.

**Interpretation:**
- $B(n,k)$ = integral of $|T_n(\cos\theta)|$ over k-th arc
- Like "local probability density" in quantum mechanics
- Sum $\sum_k B(n,k) = n$ acts as normalization (but to n, not 1)

### Spectral Zeta Analogy

Standard spectral Œ∂-function: $\zeta_L(s) = \sum_n \lambda_n^{-s} = \text{Tr}(L^{-s})$

Our formula: $\sum_n B(n,k) \cdot n^{-s} \to \eta(s)$

**Key difference:** B(n,k) introduces alternating signs through cot(œÄ/n) pole structure.

### Transfer Matrix Approach (Negative Result)

Tried constructing circulant matrix from B(n,k) values:
- Spectral radius œÅ = n always
- Determinant = 0 for n ‚â• 4 (singular)
- Does not obviously produce Œ∑(s)

**Conclusion:** The operator question remains open. B(n,k) acts as spectral weight but the underlying operator is not a simple Sturm-Liouville or transfer matrix.

## Spacing Statistics Analysis

### Setup

For fixed n, the B(n,k) values have a **degeneracy**: B(n,k) = B(n, n-k+1) due to cos symmetry.
Only n/2 unique values exist. After removing duplicates, we can compute nearest-neighbor spacing statistics.

### ‚ö†Ô∏è CORRECTION (Dec 3, 2025 evening)

Earlier analysis claimed B-values have "partial level repulsion". This was **INCORRECT**.

**Actual measurements:**

| Quantity | B-values | Poisson | GOE | GUE |
|----------|----------|---------|-----|-----|
| P(s < 0.2) | **0.52** | 0.18 | 0.03 | 0.008 |
| P(s < 0.5) | **0.55** | 0.39 | 0.18 | 0.11 |

B-values have **MORE** small spacings than Poisson, not fewer! This is because:
- B(n,k) = (1/n)(1 + Œ≤¬∑cos((2k-1)œÄ/n)) traces a cosine curve
- Adjacent k values have similar cos values ‚Üí small spacings
- This creates **clustering**, not repulsion

### Exact Asymptotic Variance

**Theorem:** For single n as n ‚Üí ‚àû, the normalized spacing variance converges to:

$$\text{Var} = \frac{\pi^2 - 8}{8} \approx 0.2337$$

**Derivation:** B values are uniformly distributed on the circle (via k ‚Üí Œ∏ = (2k-1)œÄ/n), then projected via cos to get arcsine distribution. The spacings in Œ∏ are uniform, so spacing in B ~ |sin(Œ∏)|. For Œ∏ uniform on [0,œÄ]:

- ‚ü®sin Œ∏‚ü© = 2/œÄ
- ‚ü®sin¬≤Œ∏‚ü© = 1/2
- Var[sin] = 1/2 - 4/œÄ¬≤
- Normalized variance = Var[sin]/‚ü®sin‚ü©¬≤ = **(œÄ¬≤ - 8)/8**

### Comparison to RMT Ensembles

| Ensemble | Spacing Variance |
|----------|------------------|
| Poisson (uncorrelated) | 1.000 |
| GOE (Gaussian Orthogonal) | 0.286 |
| **Arcsine (theoretical)** | **0.234** |
| GUE (Gaussian Unitary) | 0.178 |

**Note:** The variance comparison is about the theoretical arcsine distribution, not measured B-values.

### Curious Near-Miss: Œ≥ Connection

The ratio of GUE to arcsine variance squared is remarkably close to Euler-Mascheroni Œ≥:

$$\left(\frac{\text{Var}_{\text{GUE}}}{\text{Var}_{\text{arcsine}}}\right)^2 = \left(\frac{3\pi/8 - 1}{(\pi^2-8)/8}\right)^2 \approx 0.5808$$

vs Œ≥ ‚âà 0.5772 (0.6% difference)

Even more striking: **Œ≥ + 3/847 matches to 0.11 ppm** (where 847 = 7 √ó 11¬≤)

This is almost certainly coincidental given:
- Var_GUE involves œÄ (Gaussian integrals)
- Var_arcsine involves œÄ¬≤ (trig integrals)
- Œ≥ is transcendental and unrelated to œÄ

However, the general proximity (Var_GUE/Var_arcsine ‚âà ‚àöŒ≥) may hint at deeper connections between classical orthogonal polynomials and random matrix theory.

### ‚ö†Ô∏è Pair Correlation: Corrected Understanding

The earlier table with "Observed B = 0.29" was **incorrect** methodology.

**Correct understanding:**

B-values for fixed n trace a cosine curve. Adjacent B-values have similar values by construction, leading to **clustering** not repulsion.

The "partial level repulsion" claim was wrong. B-values do NOT have RMT-like correlations.

**Auto-correlation:**
- B(n,1) vs B(m,1): very high correlation (0.985 at lag 1), slowly decaying
- Within-n Corr(B(n,k), B(n,k+1)): approaches 1 as n‚Üí‚àû (smooth cosine)

This confirms B-values are **deterministic** and **highly correlated by construction**, not exhibiting random-matrix-like behavior.

## ‚ö†Ô∏è Geometric Deformation: Negative Result

### Earlier Claim (INCORRECT)

Earlier analysis claimed power-law deformation r(Œ∏) = 1 + c|cos Œ∏|^p could reproduce GUE statistics. This was **wrong**.

### Corrected Analysis (Dec 3, 2025)

**Tested deformations:**

| Deformation Type | Best P(s<0.2) achieved |
|------------------|------------------------|
| Power law r = 1 + c\|cos Œ∏\|^p | ~0.50 |
| Gaussian at poles | ~0.50 |
| Cosine (ellipse-like) | ~0.50 |
| Step function | ~0.55 |

**None approach GUE's P(s<0.2) = 0.008!**

### Why Geometric Deformation Cannot Work

**Fundamental insight:** Level repulsion requires **correlations** between points. These come from **random matrix structure**, not geometry.

- Smooth geometric transformation changes the **marginal distribution**
- It does NOT create **correlations** between consecutive spacings
- GUE repulsion (P(s) ~ s¬≤ near 0) is a **collective phenomenon** from eigenvalue dynamics

### Visualization

![Lobes with radial transformation](lobes_all_fast.png)

The visualization correctly shows Chebyshev lobes under radial transformation r(Œ∏) = 1 + |cos Œ∏|‚Å¥:
- Original: 7 lobes inside unit circle
- Transformed: Same lobes stretched at poles (x ‚âà ¬±1)

This is **geometrically correct** but does NOT produce RMT statistics.

## Jacobi Matrix: The Correct RMT Connection

### Key Discovery (Dec 3, 2025 evening)

The proper Chebyshev-RMT connection is through **Jacobi matrices**, not B-value statistics.

### Three-Term Recurrence ‚Üí Jacobi Matrix

Chebyshev polynomials satisfy:
$$T_{n+1}(x) = 2x \cdot T_n(x) - T_{n-1}(x)$$

Rearranged:
$$x \cdot T_n = \frac{1}{2}T_{n-1} + \frac{1}{2}T_{n+1}$$

This defines a **tridiagonal Jacobi matrix** $J_n$:

```
J_n = | 0   1/2   0    0   ... |
      | 1/2  0   1/2   0   ... |
      |  0  1/2   0   1/2  ... |
      | ...            ...     |
```

**Eigenvalues of J_n = Chebyshev zeros** (deterministic, cos(kœÄ/(n+1)))

### The Noise Transition: Deterministic ‚Üí GOE

**Critical finding:** Adding Gaussian noise to the Jacobi matrix transitions from deterministic to GOE statistics!

| Noise level Œµ | P(s < 0.2) |
|---------------|------------|
| 0 (deterministic) | 0.00 (all spacings identical) |
| 0.01 | **0.032** |
| 0.05 | 0.035 |
| 0.10 | 0.027 |
| 0.50 | 0.038 |
| GOE (reference) | **0.031** |

**Key observation:** Even infinitesimal noise immediately produces GOE statistics!

### Physical Interpretation

```
Deterministic Jacobi      +Œµ noise        Random Jacobi
    (Chebyshev)        ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí           (GOE)

Eigenvalues:           Eigenvalues:
  cos(kœÄ/(n+1))        have repulsion
  (no repulsion)       P(s) ~ s near 0
  P(s<0.2) = 0         P(s<0.2) ‚âà 0.03
```

### Why This Matters

1. **Chebyshev = deterministic limit** of random Jacobi matrices
2. **Arcsine distribution** = equilibrium measure (where eigenvalues concentrate)
3. **Level repulsion** requires randomness in matrix entries
4. **Geometric deformation cannot create correlations** ‚Äî only noise can

### Visualizations

![Jacobi Matrix Structure](jacobi_matrix_plot.png)

**Left:** Tridiagonal structure of Chebyshev Jacobi matrix J‚ÇÇ‚ÇÄ

![Eigenvalue Distribution](eigenvalue_distribution.png)

**Right:** Eigenvalue distribution of J‚ÇÅ‚ÇÄ‚ÇÄ follows arcsine density 1/(œÄ‚àö(1-x¬≤))

### Wigner Surmise: Closed-Form Spacing PDFs

| Ensemble | P(s) | P(s<0.2) | Repulsion |
|----------|------|----------|-----------|
| Poisson | e^{-s} | 0.181 | none |
| GOE (Œ≤=1) | (œÄ/2)s¬∑e^{-œÄs¬≤/4} | 0.031 | ~s |
| GUE (Œ≤=2) | (32/œÄ¬≤)s¬≤¬∑e^{-4s¬≤/œÄ} | 0.008 | ~s¬≤ |
| GSE (Œ≤=4) | ... | 0.0007 | ~s‚Å¥ |

![Spacing Distributions](spacing_distributions.png)

### Full Histogram Comparison (Chi-Square Test)

To verify this is NOT a coincidence at one point, we compared the ENTIRE spacing distribution:

![Histogram Comparison](histogram_comparison.png)

**Chi-square goodness of fit:**
```
œá¬≤ (Chebyshev+noise vs GOE):     0.004  ‚Üê excellent match!
œá¬≤ (Chebyshev+noise vs Poisson): 0.37   ‚Üê poor match
```

The match to GOE is nearly perfect across ALL bins, not just at P(s<0.2).

### RMT Universality: What's Special About Chebyshev?

**Key question:** Is GOE emergence special to Chebyshev, or universal?

**Test:** Various matrices + scaled Gaussian noise ‚Üí measure P(s<0.2)

| Œµ (noise) | Chebyshev | Fibonacci | Primes | PiPowers |
|-----------|-----------|-----------|--------|----------|
| 0.01 | **0.036** | 0.56 | 0.034 | 0.18 |
| 0.1 | **0.035** | 0.052 | 0.037 | 0.039 |
| 0.5 | **0.032** | 0.035 | 0.037 | 0.035 |
| 1.0 | **0.036** | 0.032 | 0.037 | 0.038 |

**GOE target: P(s<0.2) = 0.031**

**Conclusion:**
- ‚úÖ **Universality IS real** ‚Äî all matrices eventually ‚Üí GOE
- ‚ö†Ô∏è **Rate depends on structure** ‚Äî Chebyshev converges fastest (Œµ=0.01 sufficient)
- üéØ **Ratio matters** ‚Äî noise must exceed eigenvalue gap scale

**What makes Chebyshev special:**
- NOT the GOE statistics (those are universal)
- BUT the fast convergence (eigenvalue gaps are O(1/n¬≤), well-mixed)
- AND the equilibrium measure is arcsine (elegant closed form)

### Summary

The Chebyshev-RMT connection is:

1. **NOT about B-value statistics** (these are deterministic, no repulsion)
2. **IS about Jacobi matrices** (orthogonal polynomial recurrence)
3. **Noise transforms deterministic ‚Üí GOE** (level repulsion emerges)
4. **Arcsine = equilibrium measure** for Chebyshev Jacobi ensemble
5. **Full distribution match** verified by œá¬≤ test (0.004 vs GOE)
6. **Universality confirmed** ‚Äî but Chebyshev converges fastest

## Matrix Diagonalization Attempts

### Goal
Find a matrix construction from B(n,k) values whose eigenvalues relate to zeta zeros (14.135, 21.022, 25.011, ...).

### Summary of All Attempts

| Matrix Type | Construction | Eigenvalues | Match to Œ∂-zeros? |
|-------------|--------------|-------------|-------------------|
| **Gram** | G_nm = Œ£_k B(n,k)¬∑B(m,k) | Grow with N (22‚Üí110 for N=6‚Üí15) | ‚ùå No |
| **Circulant** | First row = (B(n,1), ..., B(n,n)) | Mostly zeros | ‚ùå No |
| **Toeplitz/Hankel** | T_ij = B(\|i-j\|+2, 1) | Rank-1, one eigenvalue ‚âà n | ‚ùå No |
| **Transfer** | 2√ó2 with B entries | œÅ = n trivially | ‚ùå No |
| **M[i,j] = B(i+j, i)** | Index-sum based | ~9.4, -0.5, -0.3, complex... | ‚ùå No |
| **Jacobi-modified** | diag = B(n,k), off-diag = 1/2 | Range [0.02, 1.9] | ‚ùå No |
| **3-term recurrence** | P_{k+1} = x¬∑P_k - B(n,k)¬∑P_{k-1} | Symmetric in [-1.9, 1.9] | ‚ùå No |

### Detailed Results

**Gram Matrix Eigenvalues (N √ó N):**
```
N=6:  22.3, 0.09, 0.02, ...
N=10: 46.3, 0.14, 0.04, ...
N=15: 110.0, 0.17, 0.05, ...
```
Dominant eigenvalue grows ~O(N¬≤), doesn't stabilize.

**Logarithmic Sums:**
```
Sum log(B(n,k)) / n  ‚Üí  -0.00734  as n‚Üí‚àû
(Prod B)^(1/n)       ‚Üí  0.9927    (matches geometric mean formula)
```

**Rays in (n,k) Space:**
- k = floor(Œ±¬∑n) for fixed Œ± ‚àà (0,1)
- Different limits for different rays (0.83 to 1.17)
- No special structure found

### Why Matrix Approach is Hard

The fundamental chain:
```
B(n,k)  ‚îÄ‚îÄŒ£‚îÄ‚îÄ‚Üí  Œ∑(s)  ‚îÄ‚îÄanalytic‚îÄ‚îÄ‚Üí  Œ∂(s)  ‚îÄ‚îÄsolve‚îÄ‚îÄ‚Üí  Œ≥_m
                                           Œ∂(s)=0
```

**Problem:** Step B ‚Üí Œ∑ involves infinite summation. Information about individual B values "dissolves" into the function Œ∑(s). Recovering zeros from a function defined by an infinite series is fundamentally hard.

**What would be needed:**
- A finite matrix M_N whose eigenvalues converge to zeta zeros as N ‚Üí ‚àû
- Such a matrix would "invert" the summation process
- This is essentially the Hilbert-Polya conjecture in disguise

### Conclusion

None of the natural matrix constructions from B(n,k) produce eigenvalues resembling zeta zeros. This suggests that:

1. The B ‚Üí Œ∑ ‚Üí Œ∂ path is fundamentally one-way (summation destroys structure)
2. If a spectral interpretation exists, it requires additional structure beyond B(n,k) alone
3. The connection B ‚Üí Œ∑ is beautiful but may not directly lead to zeros

## Open Questions

1. **Can we prove** Laguerre correction is exactly O(1/n)?

2. **What's the correction term** in closed form for Hermite?

3. **Can the semicircle distribution of Hermite** lead to GUE-like statistics?

4. **What operator** would have B(n,k) as its spectral characteristics?
   - Not simple Sturm-Liouville (verified)
   - Not obvious transfer matrix (verified)

5. **Is there a deeper reason** why exponential weights align with Œ∑(s)?

6. **Is the Œ≥ near-miss significant?** The ratio¬≤ ‚âà Œ≥ + 3/847 (0.11 ppm) - coincidence or connection?

## References

- Montgomery's pair correlation conjecture (1973)
- Odlyzko's numerical verification of GUE statistics for zeta zeros
- Classical potential theory and equilibrium measures

---

*Session continues from [hyperbolic-integration](../2025-12-03-hyperbolic-integration/README.md) and [primitive-lobe-signs](../2025-12-03-primitive-lobe-signs/README.md)*
